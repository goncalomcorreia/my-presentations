%! TeX program = xelatex

\documentclass[xetex,aspectratio=169,xcolor,professionalfonts,hyperref]{beamer}
\usepackage[
    style=authoryear,
    backend=biber,
    natbib,
    uniquename=false,
    maxcitenames=2,
    maxbibnames=20,
    sorting=nty]{biblatex}
\addbibresource{refs.bib}
\renewcommand*{\bibfont}{\scriptsize}
\usepackage{anyfontsize}
\usepackage{tabularx}
\usepackage{changepage}
\input{preamble}
\input{commands}

\usetikzlibrary{bayesnet}
\captionsetup[figure]{labelformat=empty}
\pgfplotsset{compat=1.16}
\newcommand\simplex{\triangle}
\newcommand\HHs{\HH^{\textsc{s}}}
\newcommand\HHg{\HH^{\textsc{g}}}
\newcommand\HHta{\HH^{\textsc{t}}_{\alpha}}
\newcommand\xv{\bs{x}}
\newcommand{\matr}[1]{\mathbf{#1}}

\newcommand{\simpledep}[2]{%
\begin{dependency}[edge style={tPeony,very thick},hide label,arc edge]%
\begin{deptext}[column sep=.3cm]#1\end{deptext}%
#2%
\end{dependency}}

\newcommand{\textover}[3][l]{%
 % #1 is the alignment, default l
 % #2 is the text to be printed
 % #3 is the text for setting the width
 \makebox[\widthof{#3}][#1]{#2}%
 }

\DeclareMathOperator{\softmax}{\mathbf{softmax}}
\DeclareMathOperator{\sparsemax}{\mathbf{sparsemax}}
\definecolor{tBleu}{RGB}{118,169,196}
\definecolor{tDY}{RGB}{217,192,102}
\title{Thesis Proposal: Neural Machine Translation with Latent Context}
\author{Gonçalo Correia}

\addtobeamertemplate{navigation symbols}{}{%
    \usebeamerfont{footline}%
    \usebeamercolor[fg]{footline}%
    \hspace{1em}%
    \insertframenumber/\inserttotalframenumber
}

\AtBeginSection[]
{
    \begin{frame}
        \frametitle{Table of Contents}
        \tableofcontents[currentsection]
    \end{frame}
}

\begin{document}

\begin{frame}
%\titlepage
\begin{tikzpicture}[remember picture, overlay]

\node[font={\color{myfg}\usebeamerfont{title}},align=center]
    at ($(current page.center) + (0, 2.5)$) {\color{myDarkYellow} Thesis Proposal:};
\node[font={\color{myfg}\usebeamerfont{title}},align=center]
    at ($(current page.center) + (0, 1.0)$) {\color{myDarkYellow} Neural Machine Translation};
\node[font={\color{myfg}\usebeamerfont{title}},align=center]
    at ($(current page.center) + (0, 0)$) {\color{myDarkYellow} with Latent Context};
\node[anchor=north,font={\color{myfg}\usebeamerfont{author}}]
    at ($(current page.center) + (0, -1.3)$)
{
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{c}
\textbf{Gonçalo Correia}
\end{tabular}
};

\node[anchor=south,font={\color{mygr}\footnotesize}]
    at (current page.south)
{
\raisebox{-0.7mm}[\height][\depth]{}
Committee: André Martins, Mário Figueiredo, Vlad Niculae, Wilker Aziz
};
\end{tikzpicture}
\end{frame}

\tikzset{%
    enc/.style={fill=tPurple!80!mybg},
    attn/.style={fill=tPeony},
    dec/.style={fill=tBlue!50!mybg},
    wvec/.style={
        inner sep=0,
        rectangle,
        rounded corners=2pt,
        minimum width=5pt,
        minimum height=18pt},
    word/.style={
        color=mygr,
        font=\itshape
    },
    netarrow/.style={->, color=mygr},
    attnedge/.style={tPeony, thick}
}

% \section{Introduction}

\begin{frame}
    \frametitle{Neural networks: big, uninterpretable, and powerful black-boxes?}
    \centering
    \only<1>{\includegraphics[width=0.7\columnwidth]{figures/beforegpt3}}
    \only<2>{\includegraphics[width=0.4\columnwidth]{figures/gpt3}}
\end{frame}

\begin{frame}
    \frametitle{Latent variables in machine translation}
    \cornercite{brown1993mathematics}
    \centering
    \includegraphics[width=0.5\columnwidth]{figures/alignments.pdf}
\end{frame}

\begin{frame}
    \frametitle{Towards transparency: latent variables}
    \fontsize{13pt}{15}\selectfont%
    \begin{itemize}
        \uncover<1->{\item Big models need big data, latent variables do not (inductive bias)}
        \uncover<2->{\item Big models are opaque, latent variables explain model's decisions}
        \uncover<3->{\item Big models are... Big! Latent variables may lead to smaller models}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Latent variables in NMT}
    \centering
    \fontsize{15pt}{15}\selectfont%
    \begin{itemize}
        \uncover<1->{\item Advances in optimization $\rightarrow$ ditch latent
        variables}
        \uncover<2->{\item Good for high-resource language, fails
        in low-resource settings}
        \uncover<3->{\item Recent work uses variational inference to have latent variables in NMT}
    \end{itemize}
\end{frame}

\begin{frame}[t,plain,fragile]%
    \frametitle{A bit of context... On Seq2Seq}%
    \cornercite{bahdanau}%
    \begin{tikzpicture}[remember picture,overlay]
        \node[anchor=south east] at (current page.south east)
            {\scriptsize Slide Credit: Vlad Niculae\strut};
    \end{tikzpicture}
    \fontsize{13pt}{15}\selectfont%
    \begin{columns}[T]
    \begin{column}{.7\textwidth}%
    \begin{tikzpicture}[node distance=0pt]
    %
    \def\bottom{-7}%
    \def\top{0}%
    \foreach[count=\i] \j in {United,Nations,elections,end,today}{
        \node[word,anchor=south] (w\i) at (1.7*\i+2, \bottom) {\strut \alt<1-11>{\j}{}};
        \uncover<2->{\node[wvec,enc,above=-2pt of w\i] (embed\i) {};}
        \uncover<3->{
            \node[wvec,enc,above=6pt of embed\i] (enc\i) {};
            \path (embed\i) edge[netarrow] (enc\i);
        }
        \uncover<4->{\node[inner sep=0, outer sep=0, above=2pt of enc\i] (src\i){};}
        \uncover<4->{\draw[fill,attnedge] (src\i) circle[radius=1pt];}
    }
    \foreach[count=\i] \j in {Eleições,das,Nações,Unidas}
    {
        \pgfmathtruncatemacro\attnslideno{2*\i+2}
        \pgfmathtruncatemacro\outslideno{2*\i+3}
        \node[word,anchor=north, visible on=<\outslideno->] (y\i) at (1.7*\i+2, \top) {\strut \alt<1-11>{\j}{}};
        \node[wvec,dec,below=-2pt of y\i, visible on=<\outslideno->] (out\i) {};
        \node[wvec,dec,below=6pt of out\i, visible on=<\outslideno->] (dec\i) {};
        \node[wvec,attn,below=6pt of dec\i,visible on=<\attnslideno->] (attn\i) {};
        \node[inner sep=0, outer sep=0, below=2pt of attn\i] (trg\i) {};
        \draw[fill,attnedge,visible on=<\attnslideno->] (trg\i) circle[radius=1pt];
        \path (attn\i) edge[netarrow,visible on=<\outslideno->] (dec\i);
        \path (dec\i)  edge[netarrow,visible on=<\outslideno->] (out\i);
    }
    \node<4->[wvec,dec,left=14pt of dec1] (dec0) {};
    \node<4-> [anchor=west] at ([xshift=3pt]dec0.south west) {\scriptsize $\bs{s}_0$};
    \path<5-> (dec0) edge[netarrow] (dec1);
    % labels
    \node<2-> [anchor=west] at ([xshift=3pt]embed2.south west) {\scriptsize $\bs{v}_j$};
    \node<3-> [anchor=west] at ([xshift=3pt]enc2.south west) {\scriptsize $\bs{h}_j$};
    \node<4-> [anchor=west] at ([xshift=3pt]attn1.south west) {\scriptsize $\bs{c}_1$};
    \node<5-> [anchor=west] at ([xshift=3pt]dec1.south west) {\scriptsize $\bs{s}_1$};
    \node<5-> [anchor=west] at ([xshift=3pt]out1.south west) {\scriptsize $\bs{y}_1$};
    % encoder bi-LSTM arrows
    \def\sh{3pt}
    \uncover<3->{
    \path ([yshift=\sh]enc1.east)  edge[netarrow] ([yshift=\sh]enc2.west);
    \path ([yshift=\sh]enc2.east)  edge[netarrow] ([yshift=\sh]enc3.west);
    \path ([yshift=\sh]enc3.east)  edge[netarrow] ([yshift=\sh]enc4.west);
    \path ([yshift=\sh]enc4.east)  edge[netarrow] ([yshift=\sh]enc5.west);
    %
    \path ([yshift=-\sh]enc2.west) edge[netarrow] ([yshift=-\sh]enc1.east);
    \path ([yshift=-\sh]enc3.west) edge[netarrow] ([yshift=-\sh]enc2.east);
    \path ([yshift=-\sh]enc4.west) edge[netarrow] ([yshift=-\sh]enc3.east);
    \path ([yshift=-\sh]enc5.west) edge[netarrow] ([yshift=-\sh]enc4.east);
    }
    %
    % decoder LSTM arrows
    \uncover<7->{\path (dec1) edge[netarrow] (dec2);}
    \uncover<9->{\path (dec2) edge[netarrow] (dec3);}
    \uncover<11->{\path (dec3) edge[netarrow] (dec4);}
    % autoregressive arrows
    \uncover<7->{\path (out1) edge[netarrow] (dec2.north west);}
    \uncover<9->{\path (out2) edge[netarrow] (dec3.north west);}
    \uncover<11->{\path (out3) edge[netarrow] (dec4.north west);}
    
    % Attention to word 1
    \uncover<4->{
    \path (src1) edge[attnedge,opacity=.5] (trg1);
    \path (src2) edge[attnedge,opacity=.2] (trg1);
    \path (src3) edge[attnedge,opacity=.8] (trg1);
    \path (src4) edge[attnedge,opacity=.2] (trg1);
    \path (src5) edge[attnedge,opacity=.2] (trg1);
    }
%
\uncover<6->{
\path (src1) edge[attnedge,opacity=.6] (trg2);
\path (src2) edge[attnedge,opacity=.6] (trg2);
\path (src3) edge[attnedge,opacity=.4] (trg2);
\path (src4) edge[attnedge,opacity=.2] (trg2);
\path (src5) edge[attnedge,opacity=.2] (trg2);
}
%
\uncover<8->{
\path (src1) edge[attnedge,opacity=.4] (trg3);
\path (src2) edge[attnedge,opacity=.9] (trg3);
\path (src3) edge[attnedge,opacity=.2] (trg3);
\path (src4) edge[attnedge,opacity=.2] (trg3);
\path (src5) edge[attnedge,opacity=.2] (trg3);
}
%
\uncover<10->{
\path (src1) edge[attnedge,opacity=.9] (trg4);
\path (src2) edge[attnedge,opacity=.4] (trg4);
\path (src3) edge[attnedge,opacity=.2] (trg4);
\path (src4) edge[attnedge,opacity=.2] (trg4);
\path (src5) edge[attnedge,opacity=.2] (trg4);
}

\uncover<2->{\node[align=right,anchor=right, left=20pt of enc1] {Encoder};}
\uncover<4->{\node[align=right,anchor=right, left=20pt of attn1,yshift=-15pt]
    {Attention};}
\uncover<5->{\node[align=right,anchor=right, left=20pt of dec1] {Decoder};}
\end{tikzpicture}
\\
\end{column}
\begin{column}{.29\textwidth}%
\centering
\uncover<4->{
\textbf{\emph{attention weights}}
\\computed with \emph{softmax}:
\\[.5\baselineskip]
\small
for some decoder state $\bs{s}_t$,
compute contextually weighted average of input $\bs{c}_t$:
\begin{align*}
z_j &= \bs{s}_t^\top \bs{W}^{(a)}\bs{h}_j \\
\pi_j &= \operatorname{softmax}_j(\bs{z}) \\
\bs{c}_t &= \sum_j \pi_j \bs{h}_j
\end{align*}
}
\end{column}
\end{columns}
\end{frame}

\begin{frame}
    \frametitle{A bit of context... on Transformers}

    \fontsize{12pt}{15}\selectfont
    \only<1-5>{\cornercite{transf}}
    \only<6>{\cornercite{devlin2018bert}}
    \begin{columns}
    \uncover<1->{
        \hspace{2mm}\vspace{-1cm}\begin{column}{0.55\columnwidth}
            What if... Attention is all you need? \\
            \vspace{0.5cm}
    }
    \uncover<2->{
        {\color{myDarkYellow} Key idea:} Instead of Recurrent Neural Networks (RNNs), let's use attention mechanisms!
        \vspace{0.25cm}
    }
        \begin{itemize}
            \uncover<3->{\item In place of the RNNs, use self-attention}
            \uncover<4->{\item Do this with multiple heads (i.e. attention mechanisms in parallel)}
            \uncover<5->{\item ... and do it through several layers}
            \uncover<6->{\item Inspiration for big general-purpose models like BERT!}
        \end{itemize}
    \end{column}

    \begin{column}{0.4\columnwidth}
    \vspace{-1.5cm}
    \begin{center}
    \includegraphics[width=0.8\columnwidth]{figures/transformer_mybg}
    \tikz[baseline,remember picture]{\node[anchor=base] (t1){};}
    \end{center}
    \end{column}
    \end{columns}

\end{frame}

\begin{frame}
    \frametitle{Outline}
    \fontsize{15pt}{15}\selectfont%
    \only<2>{\cornercite{myape2019}}
    \only<3>{\cornercite{mytransf2019}}
    \only<4>{\cornercite{myneurips2020}}
    \begin{itemize}
        \uncover<2->{\item Automatic Post-Editing (APE) using BERT (ACL 2019)}
        \uncover<3->{\item Letting Transformer learn how sparse it wants its attention (EMNLP 2019)}
        \uncover<4->{\item General strategy for efficient training discrete latent variables (NeurIPS 2020)}
        \uncover<5->{\item Future work: powerful structured latent variable models for NMT}
    \end{itemize}
\end{frame}

\section{A Simple and Effective Approach to Automatic Post-Editing with Transfer Learning}

\begin{frame}
    \frametitle{What is APE?}
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/ape.pdf}
\end{frame}

\begin{frame}
    \frametitle{BERT for APE}

    \fontsize{12pt}{15}\selectfont
    %\cornercite{transf}
    \begin{columns}
    \uncover<1->{
        \hspace{2mm}\vspace{-1cm}\begin{column}{0.55\columnwidth}
    }
    \uncover<2->{
        {\color{myDarkYellow} Key idea:} Use BERT to do APE
        \vspace{0.25cm}
    }
        \begin{itemize}
            \uncover<3->{\item Prior to this work, BERT was mainly used for simple classification tasks}
            \uncover<4->{\item We introduced an effective method to use BERT in a generation task (APE)}
            \uncover<5->{\item We achieved this via smart parameter sharing between encoder and decoder}
        \end{itemize}
    \end{column}

    \begin{column}{0.4\columnwidth}
    \vspace{-1.5cm}
    \begin{center}
    \includegraphics[width=0.8\columnwidth]{figures/bertape.pdf}
    \tikz[baseline,remember picture]{\node[anchor=base] (t1){};}
    \end{center}
    \end{column}
    \end{columns}
\end{frame}

% \begin{frame}\frametitle{Parameter sharing analysis}
%     \begin{table}[htbp]
%         \centering
%         \begin{tabular}{lcc}
%         \toprule
%          & TER$\downarrow$ & BLEU$\uparrow$ \\
%         MT Baseline & 24.76 & 62.11 \\
%         Transformer & 27.80 & 60.76 \\
%         \midrule
%         Transformer decoder & 20.33 & 69.31 \\
%         Pre-trained BERT & 20.83 & 69.11 \\
%         \hspace{1ex}\textcolor{gray}{\textit{with}}
%         CA $\leftarrow$ SA & 18.91 & 71.81 \\
%         \textover[r]
%         {\hspace{1ex}\textcolor{gray}{\textit{and}}}{\hspace{1ex}\textit{with}}
%         \textover[r]
%         {SA $\leftrightarrow$}
%         {CA $\leftarrow$} Encoder SA & \textbf{18.44} & \textbf{72.25} \\
%         \textover[r]
%         {\hspace{1ex}\textcolor{gray}{\textit{and}}}{\hspace{1ex}\textit{with}}
%         \textover[r]
%         {CA $\leftrightarrow$}{CA $\leftarrow$} SA & 18.75 & 71.83 \\
%         \textover[r]
%         {\hspace{1ex}\textcolor{gray}{\textit{and}}}{\hspace{1ex}\textit{with}}
%         \textover[r]
%         {FF $\leftrightarrow$}{CA $\leftarrow$} Encoder FF & 19.04 & 71.53 \\
%         \bottomrule
%         \end{tabular}
%             \label{tab:ablation_smt}
%     \end{table}
% \end{frame}

\section{Adaptively Sparse Transformers}

\begin{frame}
    \frametitle{Getting to know attention heads better}

    \begin{itemize}
        \uncover<1->{\item[] Attention heads may aid visualization but they are completely {\color{myDarkYellow} dense}.}
    \end{itemize}

    \bigskip

    \begin{itemize}
        \item[]<2-> Our solution is to bet on {\color{tPeony} sparsity}:
    \end{itemize}

    \begin{quote}
        {\normalfont
        \begin{itemize}
            \only<3>{\item {\color{myDarkYellow} for interpretability}}\only<2>{\item for interpretability} % sparse connections allow to be sure about which model representations were used to make a prediction
            \only<3>{\item {\color{myDarkYellow} for discovering linguistic structure}}\only<2>{\item for discovering linguistic structure} % we can redesign components based on what we find with sparsity
            \item<2-> for efficiency
        \end{itemize}}
    \end{quote}
\end{frame}

\begin{frame}
    \frametitle{
        \only<7->{{\color{myDarkYellow}Adaptively}} \only<5->{{\color{colorEntmax}Sparse}} \uncover<1->{Transformers}}

\only<1-4>{
    \fontsize{12pt}{15}\selectfont
    \cornercite{transf}
    \begin{columns}
    \hspace{2mm}\vspace{-1cm}\begin{column}{0.55\columnwidth}
    In each attention head:
    \begin{equation*}
    \bar{\matr{V}}  = \softmax\left(\frac{\matr{Q}\matr{K}^\top}{\sqrt{d_k}}\right)\matr{V}.
    \end{equation*}
    \uncover<2-4>{Attention in three places:
    \begin{itemize}
    \item Self-attention in the encoder\tikz[remember picture]{\node[coordinate] (n1) {};}}
    \uncover<3-4>{\item Self-attention in the decoder\tikz[remember picture]{\node[coordinate] (n2) {};}}
    \uncover<4>{\item Contextual attention\tikz[remember picture]{\node[coordinate] (n3) {};}}
    \end{itemize}

    % \vspace{-0.7cm}
    % \begin{align*}
    %     \uncover<2-4>{6 \text{ layers } \times 8 \text{ attention heads} &= 48}
    %     \\\uncover<3-4>{&+48}\\\only<4>{&+48=144\text{ attention heads}}
    % \end{align*}

    \end{column}
    \begin{column}{0.4\columnwidth}
    \vspace{-1.5cm}
    \begin{center}
    \includegraphics[width=0.9\columnwidth]{figures/transformer_mybg}
    \tikz[baseline,remember picture]{\node[anchor=base] (t1){};}
    \end{center}
    \end{column}
    \end{columns}

    \begin{tikzpicture}[remember picture,overlay]   %% use here too
        \uncover<2>{\path[draw=magenta,ultra thick,->](
            [xshift=2mm,yshift=1mm]n1.north) to [out=6cm,in=0,distance=-1.5cm] ([xshift=-5.13cm,yshift=2.0cm]t1.north);}
        \uncover<3>{\path[draw=magenta,ultra thick,->](
            [xshift=2mm,yshift=1mm]n2.north) to [out=6cm,in=0,distance=-3cm] ([xshift=-2.67cm,yshift=2.0cm]t1.north);}
        \uncover<4>{\path[draw=magenta,ultra thick,->](
            [xshift=2mm,yshift=1mm]n3.north) to [out=-6cm,in=0,distance=-2.5cm] ([xshift=-2.67cm,yshift=3.55cm]t1.north);}
    \end{tikzpicture}
}

\begin{itemize}
\item[]\uncover<6->{
    {\color{colorEntmax} Key idea:} replace softmax in attention heads by a sparse normalizing function! \quad\emoji{palms}
}

\bigskip

\item[]\uncover<7->{
    {\color{myDarkYellow} Another key idea:}
    use a normalizing function that is adaptively sparse via a learnable $\alpha$! \quad\emoji{palms}\enspace\emoji{palms}\enspace\emoji{palms}
}
\end{itemize}

\end{frame}

\begin{frame}[plain,t,fragile]%
    \frametitle{What is softmax?}%
    \centering \fontsize{12pt}{15}\selectfont
    Softmax exponentiates and normalizes:
    
    \begin{center}
    $\displaystyle
    \softmax(\xx_i) \defeq \frac{\exp \left(\xx_i\right)}{\sum_j \exp \left(\xx_j\right)}$
    \end{center}
    
    \bigskip

    \uncover<2->{
    {\color{myDarkYellow} It's fully dense: $\softmax(\vectsymb{z}) > \vect{0}$}}

\end{frame}

% \begin{frame}{$\Omega$-Regularized Argmax}
%     \cornercite{Niculae2017}
%     \fontsize{12pt}{15}\selectfont
%     \vspace{-0.5cm}
%     \begin{itemize}
%     \item[] For convex $\Omega$, define the {\bf $\Omega$-regularized argmax transformation}:\\
%     \bigskip
%     \begin{center}
%     $\displaystyle
%     \argmaxbf{}_{{\Omega}}(\vectsymb{z}) \defeq \arg\max_{\vectsymb{p} \in \triangle} \DP{\vectsymb{z}}{\vectsymb{p}} {\color{tPeony}- \Omega(\vectsymb{p})}$
%     \end{center}
%     \end{itemize}
%     \bigskip
%     \begin{itemize}
%     \uncover<2->{\item {\color{myDarkYellow} Argmax} corresponds to {\bf no regularization}, $\displaystyle\Omega \equiv 0$}
%     \uncover<3->{\item {\color{myDarkYellow} Softmax} amounts to {\bf entropic regularization}, $\displaystyle\Omega(\vectsymb{p}) = \sum_{i=1}^K p_i \log p_i$}
%     \uncover<4->{\item {\color{myDarkYellow} Sparsemax} amounts to {\bf $\ell_2$-regularization}, $\displaystyle\Omega(\vectsymb{p}) = \frac{1}{2}\|\vectsymb{p}\|^2$.}
%     \end{itemize}
%     \bigskip
%     \begin{itemize}
%     \item[] \uncover<5->{Is there something in-between?}
%     \end{itemize}
%     \uncover<4>{\cornercite[south east]{sparsemax}}
% \end{frame}

\begin{frame}{$\alpha$-Entmax}
    \cornercite{Peters2019ACL}
    \vspace{-1cm}
    \fontsize{12pt}{15}\selectfont
    \begin{itemize}
    \item[] Parametrized by {\color{tPeony}$\alpha \ge 0$}:
    \end{itemize}
    \bigskip
    % \begin{center}
    % $\displaystyle
    % \Omega_{{\color{tPeony}\alpha}}(\vectsymb{p}) \defeq 
    % \left\{
    % \begin{array}{ll}
    % \frac{1}{\alpha(\alpha-1)} \left(1 - \sum_{i=1}^K p_i^{\alpha}\right) & \text{if $\alpha \ne 1$}\\
    % \sum_{i=1}^K p_i\log p_i & \text{if $\alpha = 1$.}
    % \end{array}
    % \right.$
    % \end{center}
    % \bigskip
    \begin{itemize}
        \uncover<2->{\item {\bf Argmax} corresponds to {\color{tPeony}$\alpha \rightarrow \infty$}}
        \uncover<3->{\item {\bf Softmax} amounts to {\color{tPeony}$\alpha \rightarrow 1$}}
        \uncover<4->{\item {\bf Sparsemax} amounts to {\color{tPeony}$\alpha = 2$}.}
    \end{itemize}
    \bigskip
    \begin{itemize}
        \uncover<5->{\item[] {\color{myDarkYellow} Key result:} {\bf can be sparse for $\alpha > 1$}, propensity for sparsity increases with $\alpha$.}
    \end{itemize}

\end{frame}

\begin{frame}
    \centering
    \input{entmax_mappings.tex}
\end{frame}

\begin{frame}
    \frametitle{Learning $\alpha$}

    \begin{itemize}
        \uncover<2->{\item[] {\color{myDarkYellow} Key contribution}: \\\bigskip\quad a closed-form expression for $\pfrac{\aentmax(\x)}{\alpha}$ \quad\emoji{oface}}
    \end{itemize} 

\end{frame}

\begin{frame}[fragile]
    \frametitle{Head Diversity per Layer}

    \centering\fontsize{10pt}{15}\selectfont
    \begin{tikzpicture}[scale=0.9]

        \definecolor{color0}{rgb}{0.12156862745098,0.466666666666667,0.705882352941177}
        \definecolor{color1}{rgb}{1,0.498039215686275,0.0549019607843137}
        \definecolor{color2}{rgb}{0.172549019607843,0.627450980392157,0.172549019607843}
        
        \begin{groupplot}[group style={group size=1 by 1}]
        \nextgroupplot[
        legend cell align={left},
        legend style={
                nodes={scale=1.1, transform shape}, at={(0.97,0.2)}, anchor=east, draw=white!80.0!black, fill=myfg!30!mybg, fill opacity=0.6, draw opacity=1,text opacity=1},
        tick align=outside,
        tick pos=left,
        x grid style={white!69.01960784313725!black},
        xmin=0.5, xmax=6.5,
        xtick = {1, 2, 3, 4, 5, 6},
        xtick style={color=white},
        y grid style={white!69.01960784313725!black},
        ymin=0.1, ymax=0.7,
        ytick = {0.2, 0.4, 0.6},
        ylabel={Jensen-Shannon Divergence},
        ytick style={color=white}
        ]
        \addplot [thick, color0, mark=square*, mark size=3, mark options={solid}]
        table {%
        1 0.38571667343747
        2 0.402429158203537
        3 0.440747738282957
        4 0.359233941813858
        5 0.337470844946825
        6 0.339900884621234
        };
        \addlegendentry{softmax}
        \addplot [thick, color1, mark=*, mark size=3, mark options={solid}]
        table {%
        1 0.378367748537659
        2 0.504354104995477
        3 0.573529792473815
        4 0.525266398541884
        5 0.439669581263257
        6 0.421346772557364
        };
        \addlegendentry{1.5-entmax}
        \addplot [thick, color2, mark=asterisk, mark size=3, mark options={solid}]
        table {%
        1 0.427742934860258
        2 0.484287995253192
        3 0.533714455762104
        4 0.449772918584636
        5 0.3935698561848
        6 0.355665944457941
        };
        \addlegendentry{$\alpha$-entmax}
    \end{groupplot}
    \end{tikzpicture}

\end{frame}

\begin{frame}
    \frametitle{Previous Position Head}
    \vspace{-0.5cm}
    \begin{center}
    \includegraphics[width=0.9\columnwidth]{figures/head_prev_mybg}\\
    \fontsize{12pt}{15}\selectfont
    This head role was also found in \citet{specialized}! Learned {\color{myDarkYellow}$\alpha = 1.91$}.
    \end{center}

\end{frame}

\begin{frame}
    \frametitle{Interrogation-Detecting Head}
    \vspace{-0.5cm}
    \begin{center}
    \includegraphics[width=0.9\columnwidth]{figures/head_interro_mybg}\\
    \fontsize{12pt}{15}\selectfont
    Learned {\color{myDarkYellow}$\alpha = 1.05$}.
    \end{center}

\end{frame}

% \begin{frame}
%     \frametitle{Subword-Merging Head}
%     \vspace{-0.7cm}
%     \begin{columns}[T]
%         \small
%         \begin{column}{.33\textwidth}
%         \vspace{-0.1cm}
%         \centering
%         \includegraphics[width=0.9\columnwidth]{figures/bpe4}
%         \end{column}
%         \begin{column}{.33\textwidth}
%         \vspace{-0.2cm}
%         \centering
%         \includegraphics[width=\columnwidth]{figures/bpe3}
%         \end{column}
%         \begin{column}{.33\textwidth}
%         \centering
%         \includegraphics[width=0.9\columnwidth]{figures/bpe2}
%         \end{column}
%         \end{columns}

%         \begin{center}
%             \fontsize{12pt}{15}\selectfont
%             Learned {\color{myDarkYellow}$\alpha = 1.91$}.
%         \end{center}

% \end{frame}

% \begin{frame}[fragile]
%     \frametitle{Key Takeaways}
  
%       \centering\fontsize{14pt}{14}\selectfont%
%       Introduce {\color{myDarkYellow} adaptive} sparsity\\
%       for Transformers via $\alpha$-entmax with a {\color{myDarkYellow}gradient learnable $\alpha$}.
%       %
%       %
%       \vfill
%       %
%       %
%       \begin{columns}[T]
%       \small
%       \begin{column}{.33\textwidth}
%       \centering
%       \uncover<2->{
%       \textbf{\emph{adaptive sparsity}}\\[.5\baselineskip]
%       \vspace{0.2cm}
%       \includegraphics[trim=157mm 17mm 0 0, clip, width=.7\textwidth]{figures/comparison_mybg}}%
%       \end{column}
%       \begin{column}{.33\textwidth}
%       \centering
%       \uncover<3->{
%       \textbf{\emph{reduced head redundancy}}\\[\baselineskip]}
%       \vspace{-0.2cm}
%       \begin{tikzpicture}[node distance=1.5ex,font=\scriptsize,scale=0.5, visible on=<3->]
  
%           \definecolor{color0}{rgb}{0.12156862745098,0.466666666666667,0.705882352941177}
%           \definecolor{color1}{rgb}{1,0.498039215686275,0.0549019607843137}
%           \definecolor{color2}{rgb}{0.172549019607843,0.627450980392157,0.172549019607843}
          
%           \begin{groupplot}[group style={group size=1 by 1}]
%           \nextgroupplot[
%           legend cell align={left},
%           legend style={
%                   nodes={scale=1.1, transform shape}, at={(0.97,0.2)}, anchor=east, draw=white!80.0!black, fill=myfg!30!mybg},
%           tick align=outside,
%           tick pos=left,
%           x grid style={white!69.01960784313725!black},
%           xmin=0.5, xmax=6.5,
%           xtick = {1, 2, 3, 4, 5, 6},
%           xtick style={color=white},
%           y grid style={white!69.01960784313725!black},
%           ymin=0.1, ymax=0.7,
%           ytick = {0.2, 0.4, 0.6},
%           ytick style={color=white}
%           ]
%           \addplot [thick, color0, mark=square*, mark size=3, mark options={solid}]
%           table {%
%           1 0.38571667343747
%           2 0.402429158203537
%           3 0.440747738282957
%           4 0.359233941813858
%           5 0.337470844946825
%           6 0.339900884621234
%           };
%           \addlegendentry{softmax}
%           \addplot [thick, color1, mark=*, mark size=3, mark options={solid}]
%           table {%
%           1 0.378367748537659
%           2 0.504354104995477
%           3 0.573529792473815
%           4 0.525266398541884
%           5 0.439669581263257
%           6 0.421346772557364
%           };
%           \addlegendentry{1.5-entmax}
%           \addplot [thick, color2, mark=asterisk, mark size=3, mark options={solid}]
%           table {%
%           1 0.427742934860258
%           2 0.484287995253192
%           3 0.533714455762104
%           4 0.449772918584636
%           5 0.3935698561848
%           6 0.355665944457941
%           };
%           \addlegendentry{$\alpha$-entmax}
%       \end{groupplot}
%       \end{tikzpicture}
%       \end{column}
%       \begin{column}{.33\textwidth}
%       \centering
%       \uncover<4->{
%       \textbf{\emph{clearer head roles}}\\[\baselineskip]
%       \vspace{-0.2cm}
%       \includegraphics[width=.6\textwidth]{figures/bpe4}}
%       \end{column}
%       \end{columns}
  
%     %   \vfill
  
%     %   \centering
%     %   {\scriptsize
%     %   \color{mygr}
%     %   \begin{tabular}{r@{~}l@{\quad}r@{~}l}
%     %   \raisebox{-0.7mm}[\height][\depth]{\emoji{githubfg}}& \href{https://github.com/deep-spin/entmax}{\tt github.com/deep-spin/entmax} &
%     %   \raisebox{-0.4mm}[\height][\depth]{\emoji{home}}& \href{https://goncalomcorreia.github.io}{\tt goncalomcorreia.github.io}
%     %   \end{tabular}}
  
%   \end{frame}

\section{Efficient Marginalization of Discrete and Structured Latent Variables via Sparsity}

\begin{frame}
    \frametitle{Latent Variable Models}

    \begin{itemize}
        \uncover<1->{\item[] Latent variable $z$ can be }\uncover<2->{{\color{tGreen} continuous}}\uncover<3->{, {\color{tPeony} discrete}}\uncover<4->{, or {\color{tVividBlue} structured}}
    \end{itemize}
    
    \only<1-2>{\uncover<2>{
    \begin{figure}[hb]
        \centering
        \begin{subfigure}[b]{0.24\columnwidth}
            \centering
            \includegraphics[width=\columnwidth]{figures/face1.png}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.24\columnwidth}
            \centering
            \includegraphics[width=\columnwidth]{figures/face2.png}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.24\columnwidth}
            \centering
            \includegraphics[width=\columnwidth]{figures/face3.png}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.24\columnwidth}
            \centering
            \includegraphics[width=\columnwidth]{figures/face4.png}
        \end{subfigure}
        \caption{Source: \cite{faces}}
        \label{fig:rotation}
    \end{figure}
    }}

    \only<3>{
    \begin{figure}[hb]
        \centering
            \includegraphics[width=0.5\columnwidth]{figures/eyes.png}
            \caption{Source: \href{https://valleyeyecareaz.com/how-is-your-eye-color-determined/}{valleyeyecareaz.com}}
        \label{fig:eyes}
    \end{figure}
    }

    \only<4>{
    \begin{figure}[hb]
        \centering
            \includegraphics[width=0.6\columnwidth]{figures/celeba_bg.pdf}
            \caption{Source: \cite{liu2015faceattributes}}
        \label{fig:eyes}
    \end{figure}
    }

\end{frame}

\begin{frame}
    \frametitle{Training Discrete or Structured Latent Variable Models}
    \fontsize{12pt}{15}\selectfont

    \begin{columns}
    \hspace{2mm}\vspace{-1cm}\begin{column}{0.7\columnwidth}\vspace{-1cm}
    \begin{itemize}
        \uncover<1->{\item[] Latent variable $z$ can be }\uncover<2->{{\color{tPeony} discrete}}\uncover<3->{ or {\color{tVividBlue} structured}}
    \end{itemize}

    \begin{itemize}
        \uncover<4->{\item[] $\pi(z | x, \theta)$: distribution over possible $z$}
    \end{itemize}

    % besides this, there's also
    \begin{itemize}
        \uncover<7->{\item[] $\ell(x, z; \theta)$: downstream loss: ELBO, Log-Likelihood, (...)}
    \end{itemize}

    \end{column}

    \begin{column}{0.25\columnwidth}
            \vspace{-0.5cm}
            \begin{center}
                \begin{figure}[ht]
                \begin{tikzpicture}
                    % DISCRETE
                    \uncover<2->{\draw[draw=tPink,fill=tPink] (1.4,2) circle (0.2) node[anchor=south, yshift=2mm] {{\visible<5->{\color{tPeony} \small 0.2}}};}
                    \uncover<2->{\draw[draw=tSlateBlue,fill=tSlateBlue] (2,2) circle (0.2) node[anchor=south, yshift=2mm] {{\visible<5->{\color{tPeony} \small 0.6}}};}
                    \uncover<2->{\draw[draw=tGreen,fill=tGreen] (2.6,2) circle (0.2) node[anchor=south, yshift=2mm] {{\visible<5->{\color{tPeony} \small 0.1}}};}

                    % STRUCTURE
                    \uncover<3->{\draw[draw=tSlateBlue,fill=tSlateBlue] (1.4,1) circle (0.2) node[anchor=east, xshift=-2mm] {$[$};}
                    \uncover<3->{\draw[draw=tGreen,fill=tGreen] (2,1) circle (0.2);}
                    \uncover<3->{\draw[draw=tPink,fill=tPink] (2.6,1) circle (0.2)
                        node[anchor=west, xshift=2mm] {$]$}
                        node[anchor=west, xshift=5mm] {{\visible<6->{\color{tVividBlue} \small 0.4}}};}

                    \uncover<3->{\draw[draw=tPink,fill=tPink] (1.4,0.5) circle (0.2) node[anchor=east, xshift=-2mm] {$[$};}
                    \uncover<3->{\draw[draw=tSlateBlue,fill=tSlateBlue] (2,0.5) circle (0.2) node[anchor=north, yshift=-4mm] {\large \bf $\ldots$};}
                    \uncover<3->{\draw[draw=tGreen,fill=tGreen] (2.6,0.5) circle (0.2)
                        node[anchor=west, xshift=2mm] {$]$}
                        node[anchor=west, xshift=5mm] {{\visible<6->{\color{tVividBlue} \small 0.05}}};}

                    \uncover<3->{\draw[draw=tGreen,fill=tGreen] (1.4,-0.5) circle (0.2) node[anchor=east, xshift=-2mm] {$[$};}
                    \uncover<3->{\draw[draw=tSlateBlue,fill=tSlateBlue] (2,-0.5) circle (0.2);}
                    \uncover<3->{\draw[draw=tPink,fill=tPink] (2.6,-0.5) circle (0.2)
                        node[anchor=west, xshift=2mm] {$]$}
                        node[anchor=west, xshift=5mm] {{\visible<6->{\color{tVividBlue} \small 0.3}}};}
                \end{tikzpicture}
                \end{figure}
            \end{center}
    \end{column}
    \end{columns}

    \vspace{-0.5cm}

    \begin{itemize}
        \uncover<8->{\item[] To train, we need to compute the following expectation:}
    \end{itemize}

    \begin{equation*}\label{eq:fit}
        \uncover<9->{\mathcal{L}_{x}(\theta) =
        \sum_{z \in \mathcal Z}
        \pi(z | x, \theta)
        ~\ell(x, z; \theta)}
    \end{equation*}

    \begin{itemize}
        \uncover<10->
        {\item[] If $\mathcal Z$ is
        \only<10>{{\color{tPeony} large}, this sum can get very expensive due to $\ell(x, z; \theta)$!\quad\emoji{oface}}
        \only<11->{{\color{tVividBlue} combinatorial}, this can be intractable to compute!\quad\emoji{oface}\enspace\emoji{oface}\enspace\emoji{oface}}}
    \end{itemize}

\end{frame}

\begin{frame}
    \frametitle{Current Solutions}
    \fontsize{12pt}{15}\selectfont

    \begin{itemize}
        \item[] If $\mathcal Z$ is large, exact gradient computation is prohibitive
    \end{itemize}

    \bigskip

    \begin{itemize}
        \uncover<2->{\item[] One option: SFE (aka REINFORCE) $\rightarrow$ unbiased but high variance}
        \uncover<3->{\item[] Another option: Gumbel-Softmax $\rightarrow$ continuous relaxation, biased estimation}
    \end{itemize}

    \bigskip

    \begin{itemize}
        \uncover<4->{\item[] New option: {\color{tPeony} use sparsity}!\quad\emoji{palms}}
    \end{itemize}

    \begin{itemize}
        \uncover<5->{\item[] no need for sampling $\rightarrow$ no variance}
        \uncover<6->{\item[] no relaxation into the continuous space}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Taking a step back...}
    \fontsize{12pt}{15}\selectfont
    \begin{itemize}
        \item[] Does the expectation over possible $z$ need to be expensive?
    \end{itemize}

    \begin{align*}\label{eq:fit}
        \uncover<2->{\mathcal{L}_{x}(\theta) &=
        \sum_{z \in \mathcal Z}
        \pi(z | x, \theta)~\ell(x, z; \theta) \\&=
        \pi(z_1 | x, \theta)~\ell(x, z_1; \theta) + \pi(z_2 | x, \theta)~\ell(x, z_2; \theta) + \ldots \\&+ \pi(z_{\mathrlap{i}\hphantom{1}} | x, \theta)~\ell(x, z_{\mathrlap{i}\hphantom{1}}; \theta) + \ldots + \pi(z_N | x, \theta)~\ell(x, z_N; \theta)
        }
    \end{align*}

    % \begin{itemize}
    %     \uncover<3->{\item[] If components of $\pi(z | x, \theta)$ were exactly $0$, we could skip lots of computations!}
    % \end{itemize}

    \begin{itemize}
        \uncover<3->{\item[] Usually we normalize $\pi$ with $\text{softmax} \propto \exp(s) \Rightarrow \pi(z_{\mathrlap{i}\hphantom{1}} | x, \theta)>0$}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Sparse normalizers}
    \fontsize{12pt}{10}\selectfont
    \cornercite[north east]{sparsemax, sparsemap}
    \begin{itemize}
        \item[] We use {\color{tPeony} sparsemax}, {\color{tVividBlue} top-$k$ sparsemax} and {\color{tVividBlue} SparseMAP} to allow efficient marginalization
    \end{itemize}

    \begin{itemize}
        \uncover<2->{\item[] These functions are able to assign {\bf probabilities of exactly zero}!}
    \end{itemize}

    \begin{align*}
        \uncover<3->{\mathcal{L}_{x}(\theta) &=
        \sum_{z \in \mathcal Z}
        \pi(z | x, \theta)~\ell(x, z; \theta) \\&=
        \pi(z_1 | x, \theta)~\ell(x, z_1; \theta) + \alt<3>{\underbrace{\pi(z_2 | x, \theta)}_{=0}~\ell(x, z_2; \theta)}{\cancel{\underbrace{\pi(z_2 | x, \theta)}_{=0}~\ell(x, z_2; \theta)}} + \ldots \\&+
        \pi(z_{\mathrlap{i}\hphantom{1}} | x, \theta)~\ell(x, z_{\mathrlap{i}\hphantom{1}}; \theta) + \ldots + \alt<3>{\underbrace{\pi(z_N | x, \theta)}_{=0}~\ell(x, z_N; \theta)}{\cancel{\underbrace{\pi(z_N | x, \theta)}_{=0}~\ell(x, z_N; \theta)}}
        }
    \end{align*}

    \begin{itemize}
        \uncover<4->{\item[] No need for computing $\ell(x, z; \theta)$ for all $z \in \mathcal Z$!}
    \end{itemize}
\end{frame}

% \begin{frame}
%     \frametitle{Semi-Supervised VAE}%\cornerciteme{sparsemarg}

%     \newcommand*\parcolor{myfg}
%     \newcommand*\clfcolor{myfg}
%     \newcommand*\colParseZero{mybg}
%     \newcommand*\colParseNonz{mybg}
%     \renewcommand*\parcolor{tPeony}
%     \renewcommand*\clfcolor{tYellow}

%     \begin{align*}
%         \mathcal{L}_{x}(\theta) &=
%             \tikzmark{sum}\sum_{z \in \mathcal{Z}}
%             \textcolor{\parcolor}{\pi\tikzmark{parp}(z | x)}~
%             \textcolor{\clfcolor}{\ell\tikzmark{clfp}(x, z)}\\
%             &= \mathbb{E}_{z \sim \textcolor{\parcolor}{\pi(z | x)}}~%
%             \textcolor{\clfcolor}{\ell(x, z)}
%     \end{align*}

%     \vspace{\baselineskip}
%     \begin{itemize}
%     \item<1-> Semi-Supervised VAE on MNIST: $z$ is one of 10 categories
%     \item<4-> Train this with 10\% labeled data
%     \end{itemize}
%     \begin{tikzpicture}[%
%         remember picture,
%         overlay,
%         expl/.style={font=\small}]
%     \uncover<2->{
%         \node[expl,anchor=north east] (explpar)
%             at ($(current page.north east) - (.5, 2.0)$)
%             {Gaussian VAE};
%         \path (explpar.west) edge[->,very thick,bend right] ([yshift=2.0ex]{pic cs:clfp});
%     }
%     %
%     \uncover<3->{
%         \node[expl,anchor=north west,align=left] (explsum)
%             at ($(current page.west) + (.5, 1.5)$)
%             {sum over \\ the 10 digits};
%         \path (explsum.east) edge[->,very thick,bend left] ([yshift=2.5ex]{pic cs:sum});
%     }
%     \uncover<2->{
%         \node[expl,anchor=north east,align=right] (explscore)
%             at ($(current page.north east) - (.5, 3.5)$)
%             {classification network};
%         \path (explscore.south west) edge[->,very thick,bend left] ([yshift=-1.0ex]{pic cs:parp});
%     }
%     \end{tikzpicture}
% \end{frame}

% \begin{frame}
%     \frametitle{Semi-Supervised VAE}
%     \begin{columns}[T]
%     \begin{column}{.53\textwidth}
%         \centering\small%
%         \begin{tabular}{lrr}
%             \toprule
%             Method &
%             Accuracy (\%)
%             & Dec. calls\\
%             \midrule
%         \multicolumn{3}{l}{\emph{Monte Carlo}} \\
%             SFE
%             & $94.75${\tiny\color{gray}$\pm .002$} & $1$ \\
%             SFE$+$
%             & $96.53${\tiny\color{gray}$\pm .001$}  & $2$  \\
%             NVIL
%             & $96.01${\tiny\color{gray}$\pm .002$}  & $1$  \\
%             Gumbel
%             & $95.46${\tiny\color{gray}$\pm .001$}  & $1$  \\
%             \midrule
%         \multicolumn{3}{l}{\emph{Marginalization}} \\
%             Dense
%             & $96.93${\tiny\color{gray}$\pm .001$}  & $10$  \\
%             \only<2->{\textcolor{tPeony}{Sparse}
%             & $96.87${\tiny\color{gray}$\pm .001$}  & $1.01${\tiny\color{gray}$\pm 0.01$}}  \\
%             \bottomrule
%             \end{tabular}
%     \end{column}
%     \begin{column}{.47\textwidth}
%         \centering%
%         \onslide<3->{
%         \input{ssvae_elbo}
%         }
%     \end{column}
%     \end{columns}
% \end{frame}

% \begin{frame}
%     \frametitle{Emergent communication}

%     \newcommand*\parcolor{myfg}
%     \newcommand*\clfcolor{myfg}
%     \newcommand*\colParseZero{mybg}
%     \newcommand*\colParseNonz{mybg}
%     \renewcommand*\parcolor{tPeony}
%     \renewcommand*\clfcolor{tYellow}

%     \begin{align*}
%         \mathcal{L}_{x}(\theta) &=
%             \tikzmark{sum}\sum_{z \in \mathcal{Z}}
%             \textcolor{\parcolor}{\pi\tikzmark{parp}(z | x)}~
%             \textcolor{\clfcolor}{\ell(x, z)\tikzmark{clfp}}\\
%             &= \mathbb{E}_{z \sim \textcolor{\parcolor}{\pi(z | x)}}~%
%             \textcolor{\clfcolor}{\ell(x, z)}
%     \end{align*}
%     \vspace{\baselineskip}
%     \begin{itemize}
%     \item<2-> receiver picks image from a set $\mathcal{V}$ based on message
%     \item<3-> images come from ImageNet
%     \end{itemize}
%     \begin{tikzpicture}[%
%         remember picture,
%         overlay,
%         expl/.style={font=\small}]
%     \uncover<2->{
%         \node[expl,anchor=north east] (explpar)
%             at ($(current page.north east) - (.5, 1.5)$)
%             {sender};
%         \path (explpar.west) edge[->,very thick,bend right] ([yshift=3.0ex]{pic cs:parp});
%     }
%     %
%     \uncover<3->{
%         \node[expl,anchor=north west,align=left] (explsum)
%             at ($(current page.west) + (.5, 1.5)$)
%             {sum over \\ all possible messages \\ in the vocabulary};
%         \path (explsum.east) edge[->,very thick,bend left] ([yshift=3.5ex]{pic cs:sum});
%     }
%     \uncover<2->{
%         \node[expl,anchor=north east,align=right] (explscore)
%             at ($(current page.north east) - (.5, 3)$)
%             {receiver};
%         \path (explscore.south west) edge[->,very thick,bend left] ([yshift=-0.2ex, xshift=2.5ex]{pic cs:clfp});
%     }
%     \end{tikzpicture}
% \end{frame}

% \begin{frame}{Emergent Communication}\cornercite{Lazaridou2017,sparsemarg}%
%     \framesubtitle{
%     \textcolor{mygr}{... but make it harder: $|\mathcal{Z}|=256$, $|\mathcal{V}|=16$}
%     }
%     \begin{columns}[T]
%     \begin{column}{.55\textwidth}
%     \centering\small%
%     \begin{tabular}{lr@{~}lr}
%     \toprule
%     Method & \multicolumn{2}{c}{success (\%)}  & Dec. calls  \\
%     \midrule
%     {\emph{Monte Carlo}} & & & \\
%     SFE  & $33.05$&{\tiny\color{gray}$\pm 2.84$}  & $1$  \\
%     SFE$+$  & $44.32$&{\tiny\color{gray}$\pm 2.72$}  & $2$  \\
%     NVIL  & $37.04$&{\tiny\color{gray}$\pm 1.61$}  & $1$  \\
%     Gumbel     & $23.51$&{\tiny\color{gray}$\pm 16.19$}  & $1$  \\
%     ST Gumbel  & $27.42$&{\tiny\color{gray}$\pm 13.36$}  & $1$  \\
%     \midrule
%     \emph{Marginalization} & & & \\
%     \only<2->{Dense & $93.37$&{\tiny\color{gray}$\pm 0.42$}&$256$}\\
%     \only<3->{\textcolor{tPeony}{Sparse} &
%         $93.35$&{\tiny\color{gray}$\pm 0.50$} &
%         $3.13${\tiny\color{gray}$\pm 0.48$}} \\
%     \bottomrule
%     \end{tabular}
%     \end{column}
%     \begin{column}{.45\textwidth}
%     \centering%
%     \onslide<4->{
%     \input{results_emergent}
%     }
%     \end{column}
%     \end{columns}
% \end{frame}
    
\begin{frame}
    \frametitle{Results}
    \fontsize{14pt}{15}\selectfont
    \begin{itemize}
        \uncover<1->{\item[] We test our methods for models with discrete latent variables,}
        \begin{itemize}
            \uncover<2->{\item Semi-Supervised VAE}
            \uncover<3->{\item Emergent communication}
        \end{itemize}
        \uncover<4->{\item[] but also in models with an exponentially large set of $\mathcal Z$,}
        \begin{itemize}
            \uncover<5->{\item Bit-vector VAE}
        \end{itemize}
    \end{itemize}

    \begin{itemize}
        \uncover<6->{\item[] Our methods are top-performers and efficient!}
    \end{itemize}
\end{frame}

% \begin{frame}%
%     \begin{columns}%
%     \begin{column}{.45\textwidth}\centering%
%     \vbox to .9\textheight{%
%     {%
%     \fontsize{12.5pt}{13}\selectfont%
%     \setlength{\tabcolsep}{2pt}%
%     \renewcommand{\arraystretch}{2}%
%     \begin{tabular}{r r l}
%     \onslide<3->{%
%     \colorbul{colorArgmax} &
%     \textbf{argmax} &
%     $\displaystyle \argmax_{\p \in \triangle} \p ^\top \bs{s}$ \\
%     }
%     \onslide<5->{%
%     \colorbul{colorSoftmax} &
%     \textbf{softmax} &
%     $\displaystyle \argmax_{\p \in \triangle} \p ^\top \bs{s} + \HH(\p)$ \\
%     }
%     \onslide<7->{%
%     \colorbul{colorSparsemax} &
%     \textbf{sparsemax} &
%     $\displaystyle \argmax_{\p \in \triangle} \p ^\top \bs{s} - \nicefrac{1}{2} \|\p\|^2$
%     }%
%     \end{tabular}%
%     }
%     \vfill
%     \begin{tikzpicture}
%     \setupsimplexbary[2.5]{}
%     \coordinate (argmax)    at (barycentric cs:L1=0,L2=0,L3=1);
%     \coordinate (softmax)   at (barycentric cs:L1=.3,L2=.2,L3=.5);
%     \coordinate (sparsemax) at (barycentric cs:L1=.3,L2=0,L3=.7);
    
%     \onslide<3->{
%     \draw[point,fill=colorArgmax] (argmax) circle[radius=5pt];
%     }
%     \onslide<5->{
%     \draw[point,fill=colorSoftmax] (softmax) circle[radius=5pt];
%     }
%     \onslide<7->{
%     \draw[point,fill=colorSparsemax] (sparsemax) circle[radius=5pt];
%     }
%     \end{tikzpicture}}\end{column}
%     \begin{column}{.54\textwidth}\centering
%     \vbox to .9\textheight{%
%     {%
%     \fontsize{12.5pt}{13}\selectfont%
%     \setlength{\tabcolsep}{2pt}%
%     \renewcommand{\arraystretch}{2}%
%     \begin{tabular}{r l l@{\quad}}
%     \onslide<4->{%
%     \textbf{MAP} &
%     $\displaystyle \argmax_{\mg \in \Mp} \mg ^\top \bs{t}$ &
%     \colorbul{colorArgmax} \\
%     }%
%     \onslide<6->{%
%     \textbf{marginals} &
%     $\displaystyle \argmax_{\mg \in \Mp} \mg ^\top \bs{t} + \widetilde{\HH}(\mg)$ &
%     \colorbul{colorSoftmax} \\
%     }%
%     \onslide<8->{%
%     \textbf{SparseMAP} &
%     $\displaystyle \argmax_{\mg \in \Mp} \mg ^\top \bs{t} - \nicefrac{1}{2} \|\mg\|^2$ &
%     \colorbul{colorSparsemax}
%     }%
%     \end{tabular}%
%     }
%     \vfill
%     \begin{tikzpicture}[node distance=0pt]%
%     \uncover<1->{
%     \node[
%         ultra thick,
%         draw=tYellow,
%         fill=tYellow,
%         fill opacity=.15,
%         minimum size=2.5cm,
%         regular polygon, regular polygon sides=6] (mp) {};
%     \node[label=east:{\small$\Mp$}] at (mp.corner 5) {};
%     \foreach \i in {1, ..., 6}%
%     {
%         \draw[tYellow,fill] (mp.corner \i) circle[radius=3pt];
%     }
%     }
%     \coordinate (L1) at (mp.corner 3);
%     \coordinate (L2) at (mp.corner 5);
%     \coordinate (L3) at (mp.corner 2);
%     \coordinate (argmax)    at (L3);
%     \coordinate (softmax)   at (barycentric cs:L1=.25,L2=.25,L3=.45);
%     \coordinate (sparsemax) at (barycentric cs:L1=.4,L3=.6);
%     \onslide<4->{
%         \draw[point,fill=colorArgmax] (argmax) circle[radius=5pt];
%         \node[above right=of argmax] {\cartoon[.5]{1/4,2/5}};
%     }
%     \onslide<6->{
%         \draw[point,fill=colorSoftmax] (softmax) circle[radius=5pt];
%         \node[below right=of softmax] {\cartoonDense[.5]{}};
%     }
%     \onslide<8->{
%         \draw[point,fill=colorSparsemax] (sparsemax) circle[radius=5pt];
%         \node[left=of sparsemax] {\cartoonSparse[.5]{}};
%     }
%     \end{tikzpicture}}\end{column}
%     \end{columns}
%     \begin{tikzpicture}[font=\footnotesize,remember picture,overlay]
%         \node<8>[anchor=north east] at (current page.north east) {
%             \textcolor{mygr}{\realcitep*{sparsemap}}};
%     \end{tikzpicture}
%     \uncover<2>{\overlaybox[.33]{
%     $\begin{aligned}
%         \Mp &\defeq \conv \big\{ \bs{a}_z : z \in \mathcal{Z} \big\} \\
%         &= \big\{ \bs{A}\p : \p \in \triangle \big\} \\
%         &= \big\{ \mathbb{E}_{Z\sim\p}~\bs{a}_Z : \p \in \triangle \big\}
%     \end{aligned}$
%     }}
% \end{frame}

% \begin{frame}
%     \frametitle{Bit-vector VAE}
%     \newcommand*\parcolor{myfg}
%     \newcommand*\clfcolor{myfg}
%     \newcommand*\colParseZero{mybg}
%     \newcommand*\colParseNonz{mybg}
%     \renewcommand*\parcolor{tPeony}
%     \renewcommand*\clfcolor{tYellow}
%     \begin{align*}
%         \mathcal{L}_{x}(\theta) &=
%             \tikzmark{sum}\sum_{z \in \mathcal{Z}}
%             \textcolor{\parcolor}{\pi\tikzmark{parp}(z | x)}~
%             \textcolor{\clfcolor}{\ell\tikzmark{clfp}(x, z)}\\
%             &= \mathbb{E}_{z \sim \textcolor{\parcolor}{\pi(z | x)}}~%
%             \textcolor{\clfcolor}{\ell(x, z)}
%     \end{align*}
%     \begin{itemize}
%         \item<2-> VAE where $z$ is a collection of $D$ bits
%         \item<3-> Minimize the negative ELBO
%         \end{itemize}
%     \begin{tikzpicture}[%
%         remember picture,
%         overlay,
%         expl/.style={font=\small}]
%     \uncover<2->{
%         \node[expl,anchor=north east] (explpar)
%             at ($(current page.north east) - (.5, 2.0)$)
%             {generative network};
%         \path (explpar.west) edge[->,very thick,bend right] ([yshift=2.0ex]{pic cs:clfp});
%     }
%     %
%     \uncover<4->{
%         \node[expl,anchor=north west,align=left] (explsum)
%             at ($(current page.west) + (.5, 1.5)$)
%             {sum over \\ an exponetially large \\ set of structures};
%         \path (explsum.east) edge[->,very thick,bend left] ([yshift=2.5ex]{pic cs:sum});
%     }
%     \uncover<2->{
%         \node[expl,anchor=north east,align=right] (explscore)
%             at ($(current page.north east) - (.5, 3.5)$)
%             {inference network};
%         \path (explscore.south west) edge[->,very thick,bend left] ([yshift=-1.0ex]{pic cs:parp});
%     }
%     \end{tikzpicture}
% \end{frame}

% \begin{frame}{Bit-vector VAE}%
%     \begin{columns}[T]
%     \begin{column}{.53\textwidth}
%     \centering\small%
%     \begin{tabular}{lrr}
%         \toprule
%         Method & $D=32$ & $D=128$\\
%         \midrule
%     \multicolumn{3}{l}{\emph{Monte Carlo}} \\
%         SFE & $3.74$ & $3.77$  \\
%         SFE$+$ & $3.61$ & $3.59$  \\
%         NVIL & $3.65$ & $3.60$ \\
%         Gumbel & $3.57$ & $3.49$  \\
%     \midrule
%     \multicolumn{3}{l}{\emph{Marginalization}} \\
%     \color{tVividBlue}{Top-$k$ sparsemax} & $3.62$ & $3.61$  \\
%     \color{tVividBlue}{SparseMAP} & $3.72$ & $3.67$  \\
%     \color{tVividBlue}{SparseMAP (w/ budget)} & $3.64$ & $3.66$  \\
%         \bottomrule
%     \end{tabular}
%     \end{column}
%     \begin{column}{.47\textwidth}
%     \centering%
%     \only<1-2>{
%         \vspace{-0.5cm}
%         \uncover<2>{\input{distortion-rate}}
%         }
%     \only<3>{
%         \input{spars_32}
%         }
%     \only<4>{
%         \input{spars_128}
%         }
%     \end{column}
%     \end{columns}
% \end{frame}

% \begin{frame}
%     \frametitle{Key Takeaways}

%     \centering\fontsize{14pt}{14}\selectfont%
%     We introduce a new method\\
%     to train latent variable models.
%     %
%     %
%     \vfill
%     %
%     %
%     \begin{columns}[T]
%     \small
%     \begin{column}{.33\textwidth}
%     \centering
%     \uncover<2->{
%     \textbf{\emph{discrete and structured}}\\[.5\baselineskip]
%         \begin{figure}[ht]
%         \begin{tikzpicture}
%             % DISCRETE
%             \draw[draw=tPink,fill=tPink] (1.4,2) circle (0.2) node[anchor=south, yshift=2mm] {{\color{tPeony} \small 0.2}};
%             \draw[draw=tSlateBlue,fill=tSlateBlue] (2,2) circle (0.2) node[anchor=south, yshift=2mm] {{\color{tPeony} \small 0.6}};
%             \draw[draw=tGreen,fill=tGreen] (2.6,2) circle (0.2) node[anchor=south, yshift=2mm] {{\color{tPeony} \small 0.1}};

%             % STRUCTURE
%             \draw[draw=tSlateBlue,fill=tSlateBlue] (1.4,1) circle (0.2) node[anchor=east, xshift=-2mm] {$[$};
%             \draw[draw=tGreen,fill=tGreen] (2,1) circle (0.2);
%             \draw[draw=tPink,fill=tPink] (2.6,1) circle (0.2)
%                 node[anchor=west, xshift=2mm] {$]$}
%                 node[anchor=west, xshift=5mm] {{\color{tVividBlue} \small 0.4}};

%             \draw[draw=tPink,fill=tPink] (1.4,0.5) circle (0.2) node[anchor=east, xshift=-2mm] {$[$};
%             \draw[draw=tSlateBlue,fill=tSlateBlue] (2,0.5) circle (0.2) node[anchor=north, yshift=-4mm] {\large \bf $\ldots$};
%             \draw[draw=tGreen,fill=tGreen] (2.6,0.5) circle (0.2)
%                 node[anchor=west, xshift=2mm] {$]$}
%                 node[anchor=west, xshift=5mm] {{\color{tVividBlue} \small 0.05}};

%             \draw[draw=tGreen,fill=tGreen] (1.4,-0.5) circle (0.2) node[anchor=east, xshift=-2mm] {$[$};
%             \draw[draw=tSlateBlue,fill=tSlateBlue] (2,-0.5) circle (0.2);
%             \draw[draw=tPink,fill=tPink] (2.6,-0.5) circle (0.2)
%                 node[anchor=west, xshift=2mm] {$]$}
%                 node[anchor=west, xshift=5mm] {{\color{tVividBlue} \small 0.3}};
%         \end{tikzpicture}
%         \end{figure}}%
%     \end{column}
%     \begin{column}{.33\textwidth}
%     \centering
%     \uncover<3->{
%     \textbf{\emph{deterministic, yet efficient}}\\[\baselineskip]
%     \vspace{-0.5cm}
%     \fontsize{10pt}{10}\selectfont
%     \begin{align*}
%         \mathcal{L}_{x}(\theta) &= \pi(z_1 | x, \theta)~\ell(x, z_1; \theta) \\&+ \cancel{\underbrace{\pi(z_2 | x, \theta)}_{=0}~\ell(x, z_2; \theta)} \\&+ \ldots +
%         \pi(z_{\mathrlap{i}\hphantom{1}} | x, \theta)~\ell(x, z_{\mathrlap{i}\hphantom{1}}; \theta) \\&+ \ldots + \cancel{\underbrace{\pi(z_N | x, \theta)}_{=0}~\ell(x, z_N; \theta)}
%     \end{align*}}
%     \end{column}
%     \begin{column}{.33\textwidth}
%     \centering
%     \uncover<4->{
%     \textbf{\emph{sparse, as needed}}\\[\baselineskip]
%     \input{results_emergent_small}}
%     \end{column}
%     \end{columns}

%     \vfill

%     \centering
% \end{frame}

\section{Proposed Work}

\begin{frame}
    \frametitle{Latent variables in NMT}
    \centering
    \fontsize{13pt}{15}\selectfont%
    \begin{itemize}
        \uncover<1->{\item[] Attention can be seen as learning a soft structure $\rightarrow$ we saw that many attention heads have very specific and simple roles...}
        \uncover<2->{\item attention between the src and tgt is similar to the alignments we've seen before}
    \end{itemize}

    \vspace{1cm}
    \centering
    \uncover<2->{\includegraphics[width=0.5\columnwidth]{figures/alignments.pdf}}

\end{frame}

\begin{frame}
    \frametitle{Idea: create a latent, draft translation}
    \centering

    \begin{itemize}
        \uncover<1->{\item[] ... with a memory of phrase alignments}
    \end{itemize}

    \centering
    \uncover<2->{\includegraphics[width=0.8\columnwidth]{figures/nmtdrafts.pdf}}

\end{frame}

\begin{frame}
    \frametitle{Another Idea: using latent summaries in NMT}

    \centering
    \uncover<2->{\includegraphics[width=0.8\columnwidth]{figures/summary.pdf}}

\end{frame}

\begin{frame}[t,allowframebreaks]
\frametitle{References}
\printbibliography
\end{frame}

\begin{frame}
    \frametitle{Using latent summaries in NMT}

    \begin{figure}[t]
        \centering
        \begin{tikzpicture}
            % Define nodes
            \node[obs]                (y)     {\color{tMidnight} $ y $};
            \node[obs, left =of y]   (xi) {\color{tMidnight} $ X $};
            \node[latent, above =of xi] (z) {\color{tMidnight} $ z $};
    
            % Connect nodes
            \edge{xi,z}{y};
            \edge{xi}{z};
    
            \plate{data}{(y)}{$N$};
        \end{tikzpicture}
        ~
        \begin{tikzpicture}
            % Define nodes
            \node[obs]                (y)     {\color{tMidnight} $ y $};
            \node[obs, right =of y]   (xi) {\color{tMidnight} $ X $};
            \node[latent, above =of xi] (z) {\color{tMidnight} $ z $};
    
            % Connect nodes
            \edge[dashed]{xi,y}{z};
            
            \plate{data}{(y)}{$N$};
        \end{tikzpicture}
    \end{figure}
\end{frame}

\begin{frame}
    \frametitle{Multi-domain NMT}

    \begin{figure}[t]
        \centering
        \begin{tikzpicture}
            % Define nodes
            \node[obs]                (x)     {\color{tMidnight} $ x $};
            \node[obs, below =of x]   (y) {\color{tMidnight} $ y $};
            \node[latent, right =of y] (z) {\color{tMidnight} $ z $};
            \node[latent, above =of x, xshift=1.75cm] (c) {\color{tMidnight} $ c $};
    
            % Connect nodes
            \edge{x,z}{y};
            \edge{c}{z};
            \edge{x}{c};
    
            \plate{data}{(y)(x)(z)}{$N$};
        \end{tikzpicture}
        ~
        \begin{tikzpicture}
            % Define nodes
            \node[obs]                (x)     {\color{tMidnight} $ x $};
            \node[obs, below =of x]   (y) {\color{tMidnight} $ y $};
            \node[latent, right =of y] (z) {\color{tMidnight} $ z $};
            \node[latent, above =of x, xshift=1.75cm] (c) {\color{tMidnight} $ c $};
    
            % Connect nodes
            \edge[dashed]{y}{z};
            \edge[dashed]{x,y}{c};
            
            \plate{data}{(x)(y)(z)}{$N$};
        \end{tikzpicture}
    \end{figure}
\end{frame}

\begin{frame}
    \frametitle{Document-level NMT}

    \begin{figure}[t]
        \centering
        \begin{tikzpicture}
            % Define nodes
            \node[obs]                (y)     {\color{tMidnight} $ y $};
            \node[latent, above =of y] (z) {\color{tMidnight} $ z $};
            \node[latent, left =of z] (c) {\color{tMidnight} $ c $};
            \node[obs, left =of y]   (xi) {\color{tMidnight} $ X $};
    
            % Connect nodes
            \edge{xi,z}{y};
            \edge{c}{z};
            \edge{xi}{c};
    
            \plate{data}{(y)(z)}{$N$};
        \end{tikzpicture}
        ~
        \begin{tikzpicture}
            % Define nodes
            \node[obs]                (y)     {\color{tMidnight} $ y $};
            \node[latent, above =of y] (z) {\color{tMidnight} $ z $};
            \node[latent, right =of z] (c) {\color{tMidnight} $ c $};
            \node[obs, right =of y]   (xi) {\color{tMidnight} $ X $};
            
            % Connect nodes
            \edge[dashed]{y}{z};
            \edge[dashed]{y,xi}{c};
            
            \plate{data}{(y)(z)}{$N$};
        \end{tikzpicture}
    \end{figure}
\end{frame}

\end{document}

