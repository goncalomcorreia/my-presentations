@article{pressattn,
  title   = {You May Not Need Attention},
  author  = {Press, Ofir and Smith, Noah A},
  journal = {arXiv preprint arXiv:1810.13409},
  year    = {2018}
}

@article{Brucker1984,
  title     = {\href{https://www.sciencedirect.com/science/article/pii/0167637784900105}{An
               $O(n)$ algorithm for quadratic knapsack problems}},
  author    = {Brucker, Peter},
  journal   = {Operations Research Letters},
  volume    = {3},
  number    = {3},
  pages     = {163--166},
  year      = {1984},
  publisher = {Elsevier}
}

@inproceedings{junczys2018ms,
  title     = {\href{https://www.statmt.org/wmt18/pdf/WMT095.pdf}{MS-UEdin Submission to the WMT2018 APE Shared Task: Dual-Source Transformer for Automatic Post-Editing}},
  author    = {Junczys-Dowmunt, Marcin and Grundkiewicz, Roman},
  booktitle = {Proceedings of WMT18},
  year      = {2018}
}

@inproceedings{treviso2021PredictingAttentionSparsity,
  title     = {\href{http://arxiv.org/abs/2109.12188}{Predicting {{Attention Sparsity}} in {{Transformers}}}},
  author    = {Treviso, Marcos and G{\'o}is, Ant{\'o}nio and Fernandes, Patrick and Fonseca, Erick and Martins, Andr{\'e} F. T.},
  year      = {2022},
  booktitle = {Proceedings of SPNLP}
}

@inproceedings{zhang2021SparseAttentionLinear,
  title     = {\href{http://arxiv.org/abs/2104.07012}{Sparse {{Attention}} with {{Linear Units}}}},
  booktitle = {Proceedings of {{EMNLP}}},
  author    = {Zhang, Biao and Titov, Ivan and Sennrich, Rico},
  year      = {2021}
}

@inproceedings{raganato2020FixedEncoderSelfAttention,
  title     = {\href{https://arxiv.org/abs/2002.10260}{Fixed {{Encoder Self}}-{{Attention Patterns}} in {{Transformer}}-{{Based Machine Translation}}}},
  booktitle = {Proceedings of {{EMNLP}}},
  author    = {Raganato, Alessandro and Scherrer, Yves and Tiedemann, J{\"o}rg},
  year      = {2020}
}

@inproceedings{lee2020POSTECHETRISubmissionWMT2020,
  title     = {\href{https://aclanthology.org/2020.wmt-1.82.pdf}{{{POSTECH-ETRI}}'s {{Submission}} to the {{WMT2020 APE Shared Task}}: {{Automatic Post-Editing}} with {{Cross-lingual Language Model}}}},
  booktitle = {Proceedings of {{WMT}}},
  author    = {Lee, Jihyung and Lee, WonKee and Shin, Jaehun and Jung, Baikjin and Kim, Young-Kil and Lee, Jong-Hyeok},
  year      = {2020}
}

@inproceedings{kodama2020GeneratingResponsesthat,
  title     = {\href{https://aclanthology.org/2020.lrec-1.668/}{Generating {{Responses}} That {{Reflect Meta Information}} in {{User-Generated Question Answer Pairs}}}},
  booktitle = {Proceedings of {{LREC}}},
  author    = {Kodama, Takashi and Higashinaka, Ryuichiro and Mitsuda, Koh and Masumura, Ryo and Aono, Yushi and Nakamura, Ryuta and Adachi, Noritake and Kawabata, Hidetoshi},
  year      = {2020}
}

@article{Held1974,
  title     = {\href{https://link.springer.com/article/10.1007/BF01580223}{Validation
               of subgradient optimization}},
  author    = {Held, Michael and Wolfe, Philip and Crowder, Harlan P},
  journal   = {Mathematical Programming},
  volume    = {6},
  number    = {1},
  pages     = {62--88},
  year      = {1974},
  publisher = {Springer}
}

@article{Condat2016,
  title     = {\href{https://hal.archives-ouvertes.fr/hal-01056171}{Fast projection onto the simplex and the $\ell_1$ ball}},
  author    = {Condat, Laurent},
  journal   = {Mathematical Programming},
  volume    = {158},
  number    = {1-2},
  pages     = {575--585},
  year      = {2016},
  publisher = {Springer}
}

@article{danskin_theorem,
  title   = {\href{https://epubs.siam.org/doi/abs/10.1137/0114053}{The theory of max-min, with applications}},
  author  = {Danskin, John M},
  journal = {SIAM Journal on Applied Mathematics},
  volume  = {14},
  number  = {4},
  pages   = {641--664},
  year    = {1966}
}  

@inproceedings{sparsemax,
  title     = {\href{https://arxiv.org/abs/1602.02068}
               {From softmax to sparsemax: A sparse model of attention and multi-label
               classification}},
  author    = {Martins, Andr\'{e} FT and Astudillo, Ram{\'o}n Fernandez},
  booktitle = {Proc. of ICML},
  year      = {2016}
}

@inproceedings{sparseattn,
  title     = {\href{https://arxiv.org/abs/1705.07704}{A regularized framework for
               sparse and structured neural attention}},
  author    = {Niculae, Vlad and Blondel, Mathieu},
  booktitle = {Proc. of NeurIPS},
  year      = {2017}
}

@article{dantzig,
  title   = {\href{https://msp.org/pjm/1955/5-2/pjm-v5-n2-s.pdf}{The
             generalized simplex method for minimizing a linear form under linear inequality restraints}},
  author  = {Dantzig, George B and Orden, Alex and Wolfe, Philip},
  journal = {Pacific Journal of Mathematics},
  volume  = {5},
  number  = {2},
  pages   = {183--195},
  year    = {1955}
}

@inproceedings{sparsemap,
  title     = {\href{https://arxiv.org/abs/1802.04223}{SparseMAP: Differentiable sparse structured inference}},
  author    = {Niculae, Vlad and Martins, Andr{\'e} FT and Blondel, Mathieu and Cardie, Claire},
  booktitle = {Proc. of ICML},
  year      = {2018}
}

@inproceedings{esim,
  title     = {\href{https://www.aclweb.org/anthology/P17-1152}{Enhanced {LSTM} for natural language inference}},
  author    = {Chen, Qian and Zhu, Xiaodan and Ling, Zhen-Hua and Wei, Si and Jiang, Hui and Inkpen, Diana},
  booktitle = {Proc. of ACL},
  year      = {2017}
}

@inproceedings{structured_attn,
  title     = {\href{https://arxiv.org/abs/1702.00887}{Structured attention
               networks}},
  author    = {Kim, Yoon and Denton, Carl and Hoang, Loung and Rush, Alexander M},
  booktitle = {Proc. of ICLR},
  year      = {2017}
}

@conference{DSmithSmith2007,
  title     = {\href{www.aclweb.org/anthology/D07-1014}{Probabilistic models of nonprojective dependency trees}},
  author    = {Smith, David A and Smith, Noah A},
  booktitle = {Proc. of EMNLP},
  year      = {2007}
}

@inproceedings{McDonald2007,
  title     = {\href{https://dl.acm.org/citation.cfm?id=1621410.1621426}{On the complexity of non-projective data-driven dependency parsing}},
  booktitle = {Proc. of ICPT},
  author    = {McDonald, Ryan T and Satta, Giorgio},
  year      = {2007}
}

@inproceedings{koo-mt,
  title     = {\href{http://www.aclweb.org/anthology/D07-1015}{Structured prediction models via the matrix-tree theorem}},
  author    = {Koo, Terry and Globerson, Amir and Carreras P{\'e}rez, Xavier and Collins, Michael},
  booktitle = {Proc. of EMNLP},
  year      = {2007}
}

@article{lapata,
  title   = {\href{https://arxiv.org/abs/1705.09207}{Learning structured text representations}},
  author  = {Liu, Yang and Lapata, Mirella},
  journal = {TACL},
  volume  = {6},
  pages   = {63--75},
  year    = {2018}
}

@inproceedings{specialized,
  title     = {\href{https://arxiv.org/abs/1905.09418}{Analyzing multi-head self-attention: Specialized heads do the heavy lifting, the rest can be pruned}},
  author    = {Voita, Elena and Talbot, David and Moiseev, Fedor and Sennrich, Rico
               and Titov, Ivan},
  booktitle = {Proc. ACL},
  year      = {2019}
}

@inproceedings{Malaviya2018ACL,
  title     = {{Sparse and constrained attention for neural machine translation}},
  author    = {Chaitanya Malaviya and Pedro Ferreira and Martins, Andr\'e FT},
  booktitle = {Proc. of ACL},
  year      = {2018}
}
@inproceedings{easy,
  title     = {Learning What's Easy: Fully Differentiable Neural Easy-First Taggers},
  author    = {Martins, Andr{\'e} FT and Kreutzer, Julia},
  booktitle = {Proc. of EMNLP},
  pages     = {349--362},
  year      = {2017}
}

@phdthesis{taskar-thesis,
  title  = {\href{https://homes.cs.washington.edu/~taskar/pubs/thesis.pdf}{Learning structured prediction models: A large margin approach}},
  school = {Stanford University},
  author = {Ben Taskar},
  year   = {2004}
}

@article{valiant,
  title     = {\href{https://doi.org/10.1016/0304-3975(79)90044-6}{The complexity of computing the permanent}},
  author    = {Valiant, Leslie G},
  journal   = {Theor. Comput. Sci.},
  volume    = {8},
  number    = {2},
  pages     = {189--201},
  year      = {1979},
  publisher = {Elsevier}
}

@inproceedings{treelstm,
  title     = {\href{https://arxiv.org/abs/1503.00075}{Improved semantic
               representations from tree-structured Long
               Short-Term Memory networks}},
  author    = {Tai, Kai Sheng and Socher, Richard and Manning, Christopher D},
  booktitle = {Proc. of ACL-IJCNLP},
  year      = {2015}
}

@inproceedings{sparsemapcg,
  title     = {\href{https://arxiv.org/abs/1809.00653}{Towards dynamic computation graphs via sparse latent
               structure}},
  author    = {Niculae, Vlad and Martins, Andr{\'e} FT and Cardie, Claire},
  booktitle = {Proc. of EMNLP},
  year      = {2018}
}

@article{hill,
  title   = {\href{https://arxiv.org/abs/1504.00548}{Learning to understand phrases by embedding the dictionary}},
  author  = {Hill, Felix and Cho, KyungHyun and Korhonen, Anna and Bengio, Yoshua},
  journal = {TACL},
  volume  = {4},
  number  = {1},
  pages   = {17--30},
  year    = {2016}
}

@article{Rabiner1989,
  author  = {Lawrence R. Rabiner},
  title   = {\href{https://doi.org/10.1109/5.18626}{A tutorial on Hidden Markov
             Models and selected
             applications in speech recognition}},
  journal = {P. IEEE},
  year    = {1989},
  volume  = {77},
  number  = {2},
  pages   = {257--286}
}

@inproceedings{hiera,
  title     = {Hierarchical attention networks for document classification},
  author    = {Yang, Zichao and Yang, Diyi and Dyer, Chris and He, Xiaodong and Smola, Alex and Hovy, Eduard},
  booktitle = {Proc. of NAACL-HLT},
  year      = {2016}
}

@inproceedings{memntn,
  title     = {End-to-end memory networks},
  author    = {Sukhbaatar, Sainbayar and Weston, Jason and Fergus, Rob},
  booktitle = {Proc. of NeurIPS},
  year      = {2015}
}

@article{ntm,
  title   = {Neural Turing Machines},
  author  = {Alex Graves and Greg Wayne and Ivo Danihelka},
  journal = {arXiv preprint arXiv:1410.5401},
  year    = {2014}
}

@article{Child2019,
  title   = {Generating long sequences with sparse transformers},
  author  = {Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
  journal = {arXiv preprint arXiv:1904.10509},
  year    = {2019}
}

@article{Sukhbaatar2019,
  title   = {Adaptive Attention Span in Transformers},
  author  = {Sukhbaatar, Sainbayar and Grave, Edouard and Bojanowski, Piotr and Joulin, Armand},
  journal = {arXiv preprint arXiv:1905.07799},
  year    = {2019}
}

@article{Niculae2017,
  title   = {A Regularized Framework for Sparse and Structured Neural Attention},
  author  = {Niculae, Vlad and Blondel, Mathieu},
  journal = {arXiv preprint arXiv:1705.07704},
  year    = {2017}
}

@inproceedings{transf,
  title     = {Attention Is All You Need},
  author    = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  booktitle = {Proc. of NeurIPS},
  year      = {2017}
}

@inproceedings{selfattn,
  title     = {Long Short-Term Memory-Networks for Machine Reading},
  author    = {Jianpeng Cheng and Li Dong and Mirella Lapata},
  booktitle = {Proc. of EMNLP},
  year      = {2016}
}

@article{fused_lasso,
  title   = {\href{https://web.stanford.edu/group/SOL/papers/fused-lasso-JRSSB.pdf}
             {Sparsity and smoothness via the fused lasso}},
  author  = {Tibshirani, Robert and Saunders, Michael and Rosset, Saharon and Zhu, Ji and Knight, Keith},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume  = {67},
  number  = {1},
  pages   = {91--108},
  year    = {2005}
}

@inproceedings{bahdanau,
  title     = {\href{https://arxiv.org/abs/1409.0473}
               {Neural machine translation by jointly learning to align and
               translate}},
  author    = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle = {Proc. of ICLR},
  year      = {2015}
}

@inproceedings{luong,
  title     = {\href{https://arxiv.org/abs/1508.04025}
               {Effective approaches to attention-based neural machine translation}},
  author    = {Luong, Minh-Thang and Pham, Hieu and Manning, Christopher D},
  booktitle = {Proc. of EMNLP},
  year      = {2015}
}

@article{danskin,
  title   = {\href{https://epubs.siam.org/doi/abs/10.1137/0114053}{The theory of max-min, with applications}},
  author  = {Danskin, John M},
  journal = {SIAM Journal on Applied Mathematics},
  volume  = {14},
  number  = {4},
  pages   = {641--664},
  year    = {1966}
}  

@book{bertsekas-nonlin,
  title     = {\href{http://www.athenasc.com/nonlinbook.html}{Nonlinear Programming}},
  author    = {Bertsekas, Dimitri P},
  year      = {1999},
  publisher = {Athena Scientific Belmont}
}

@book{nocedalwright,
  title     = {\href{https://doi.org/10.1007/b98874}{Numerical Optimization}},
  author    = {Nocedal, Jorge and Wright, Stephen},
  year      = {1999},
  publisher = {Springer New York}
}

@article{fw,
  title     = {\href{https://doi.org/10.1002/nav.3800030109}{An algorithm for quadratic programming}},
  author    = {Frank, Marguerite and Wolfe, Philip},
  journal   = {Nav. Res. Log.},
  volume    = {3},
  number    = {1-2},
  pages     = {95--110},
  year      = {1956},
  publisher = {Wiley Online Library}
}

@inproceedings{cg,
  title     = {\href{https://arxiv.org/abs/1511.05932}{On the global linear convergence of Frank-Wolfe optimization variants}},
  author    = {Lacoste-Julien, Simon and Jaggi, Martin},
  booktitle = {Proc. of NeurIPS},
  year      = {2015}
}

@inproceedings{vinyes,
  title     = {\href{http://proceedings.mlr.press/v54/vinyes17a.html}{
               Fast column generation for atomic norm regularization}},
  author    = {Marina Vinyes and Guillaume Obozinski},
  booktitle = {Proc. of AISTATS},
  year      = {2017}
}

@article{mnp,
  title     = {\href{https://link.springer.com/article/10.1007/BF01580381}{Finding the
               nearest point in a polytope}},
  author    = {Wolfe, Philip},
  journal   = {Mathematical Programming},
  volume    = {11},
  number    = {1},
  pages     = {128--149},
  year      = {1976},
  publisher = {Springer}
}

@inproceedings{dmgcn,
  title     = {\href{http://aclweb.org/anthology/D17-1159}{Encoding sentences with graph convolutional networks for semantic
               role labeling}},
  url       = {http://aclweb.org/anthology/D17-1159},
  doi       = {10.18653/v1/D17-1159},
  booktitle = {Proc. of {EMNLP}},
  author    = {Marcheggiani, Diego and Titov, Ivan},
  year      = {2017}
}

@inproceedings{tkgcn,
  title     = {\href{https://arxiv.org/abs/1609.02907}{Semi-supervised
               classification with graph convolutional networks}},
  url       = {http://arxiv.org/abs/1609.02907},
  booktitle = {Proc. of {ICLR}},
  author    = {Kipf, Thomas N. and Welling, Max},
  year      = {2017}
}

@inproceedings{optnet,
  title     = {\href{http://proceedings.mlr.press/v70/amos17a.html}{OptNet: Differentiable optimization as a layer in neural networks}},
  url       = {http://proceedings.mlr.press/v70/amos17a.html},
  booktitle = {Proc. of ICML},
  author    = {Amos, Brandon and Kolter, J. Zico},
  year      = {2017}
}

@article{gould,
  title   = {\href{https://arxiv.org/abs/1607.05447}{On differentiating parameterized argmin and argmax problems with application to bi-level optimization}},
  url     = {http://arxiv.org/abs/1607.05447},
  journal = {preprint arXiv:1607.05447},
  author  = {Gould, Stephen and Fernando, Basura and Cherian, Anoop and Anderson, Peter and Cruz, Rodrigo Santa and Guo, Edison},
  year    = {2016}
}


@inproceedings{fylosses,
  author    = {Blondel, Mathieu and Martins, Andr\'{e} FT and Niculae, Vlad},
  title     = {\href{https://arxiv.org/abs/1805.09717}{Learning classifiers with
               Fenchel-Young losses: Generalized entropies, margins, and
               algorithms}},
  booktitle = {Proc. AISTATS},
  year      = 2019
}

@article{fylossesext,
  title   = {\href{https://arxiv.org/abs/1901.02324}{Learning with Fenchel-Young Losses}},
  author  = {Blondel, Mathieu and Martins, Andr{\'e} FT and Niculae, Vlad},
  journal = {preprint arXiv:1901.02324},
  year    = {2019}
}

@article{Tsallis1988,
  title   = {\href{https://link.springer.com/article/10.1007/BF01016429}{Possible generalization of Boltzmann-Gibbs statistics}},
  author  = {Constantino Tsallis},
  journal = {Journal of Statistical Physics},
  year    = {1988},
  volume  = {52},
  pages   = {479--487}
}

@inproceedings{bensigmorph,
  title     = {{IT-IST at the SIGMORPHON 2019 shared task: Sparse two-headed models
               for inflection}},
  author    = {Ben Peters and Martins, Andr\'{e} FT},
  year      = 2019,
  booktitle = {Proc. SIGMORPHON}
}

@inproceedings{Peters2019ACL,
  author    = {Ben Peters and Vlad Niculae and Andr\'e F.~T.~Martins},
  title     = {Sparse Sequence-to-Sequence Models},
  booktitle = {Proceedings of the  Annual Meeting of the Association for Computational Linguistics},
  year      = {2019}
}

@article{faces,
  author  = {Bouges, Pierre and Chateau, Thierry and Blanc, Christophe and Loosli, Gaëlle},
  year    = {2013},
  month   = {12},
  pages   = {55},
  title   = {Handling missing weak classifiers in boosted cascade: application to multiview and occluded face detection},
  volume  = {2013},
  journal = {EURASIP Journal on Image and Video Processing},
  doi     = {10.1186/1687-5281-2013-55}
}

@inproceedings{liu2015faceattributes,
  title     = {Deep Learning Face Attributes in the Wild},
  author    = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
  booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
  month     = {December},
  year      = {2015}
}

@inproceedings{sparsemarg,
  title     = {\href{https://arxiv.org/abs/2007.01919}{Efficient marginalization
               of discrete and structured latent variables via sparsity}},
  author    = {Correia, Gonçalo M. and Niculae, Vlad and Aziz, Wilker and Martins, Andr{\'e} FT},
  year      = 2020,
  booktitle = {Proc. NeurIPS}
}

@inproceedings{Lazaridou2017,
  author    = {Lazaridou, Angeliki and Peysakhovich, Alexander and Baroni, Marco},
  booktitle = {Proc. ICLR},
  title     = {\href{http://arxiv.org/abs/1612.07182}{Multi-agent cooperation and the emergence of (natural) language}},
  year      = {2017}
}

@inproceedings{kyrillidis2013sparse,
  title     = {\href{http://proceedings.mlr.press/v28/kyrillidis13.pdf}{Sparse projections onto the simplex}},
  author    = {Kyrillidis, Anastasios and Becker, Stephen and Cevher, Volkan and Koch, Christoph},
  booktitle = {Proc. ICML},
  year      = {2013}
}

@inproceedings{sparseseq,
  title     = {\href{https://arxiv.org/abs/1905.05702}{Sparse sequence-to-sequence models}},
  author    = {Ben Peters and Niculae, Vlad and Martins, Andr{\'e} FT},
  year      = 2019,
  booktitle = {Proc. ACL}
}

@article{grunwald_2004,
  title     = {\href{https://arxiv.org/abs/math/0410076}{Game theory, maximum entropy, minimum discrepancy and robust
               Bayesian decision theory}},
  author    = {Gr{\"u}nwald, Peter D and Dawid, A Philip},
  journal   = {Annals of Statistics},
  pages     = {1367--1433},
  year      = {2004},
  publisher = {JSTOR}
}

@article{brown1993mathematics,
  title   = {The mathematics of statistical machine translation: Parameter estimation},
  author  = {Brown, Peter F and Della Pietra, Stephen A and Della Pietra, Vincent J and Mercer, Robert L},
  journal = {Computational linguistics},
  volume  = {19},
  number  = {2},
  pages   = {263--311},
  year    = {1993}
}

@inproceedings{devlin2018bert,
  title     = {\href{https://arxiv.org/abs/1810.04805}{BERT: Pre-training of deep bidirectional transformers for
               language understanding}},
  author    = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle = {Proc. NAACL-HLT},
  year      = {2019}
}

@inproceedings{mytransf2019,
  title     = {\href{https://arxiv.org/abs/1909.00015}{Adaptively sparse transformers}},
  author    = {Correia, Gon{\c{c}}alo M and Niculae, Vlad and Martins, Andr{\'e} FT},
  booktitle = {Proc. EMNLP},
  year      = {2019}
}

@inproceedings{myneurips2020,
  title     = {Efficient {{Marginalization}} of {{Discrete}} and {{Structured Latent Variables}} via {{Sparsity}}},
  booktitle = {Proc. {{NeurIPS}}},
  author    = {Correia, Gon{\c c}alo M. and Niculae, Vlad and Aziz, Wilker and Martins, Andr{\'e} F. T.},
  year      = {2020},
  url       = {https://arxiv.org/abs/2007.01919}
}

@inproceedings{myape2019,
  title     = {A Simple and Effective Approach to Automatic Post-Editing with Transfer Learning},
  author    = {Correia, Gon{\c{c}}alo M.  and
               Martins, Andr{\'e} F. T.},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2019},
  address   = {Florence, Italy},
  publisher = {Association for Computational Linguistics},
  url       = {https://www.aclweb.org/anthology/P19-1292},
  doi       = {10.18653/v1/P19-1292},
  pages     = {3050--3056},
  abstract  = {Automatic post-editing (APE) seeks to automatically refine the output of a black-box machine translation (MT) system through human post-edits. APE systems are usually trained by complementing human post-edited data with large, artificial data generated through back-translations, a time-consuming process often no easier than training a MT system from scratch. in this paper, we propose an alternative where we fine-tune pre-trained BERT models on both the encoder and decoder of an APE system, exploring several parameter sharing strategies. By only training on a dataset of 23K sentences for 3 hours on a single GPU we obtain results that are competitive with systems that were trained on 5M artificial sentences. When we add this artificial data our method obtains state-of-the-art results.}
}
